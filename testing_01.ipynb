{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa27632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "class ConvAutoencoder:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, filters=(32, 64), latentDim=16):\n",
    "\t\t# initialize the input shape to be \"channels last\" along with\n",
    "\t\t# the channels dimension itself\n",
    "\t\t# channels dimension itself\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\t\t# define the input to the encoder\n",
    "\t\tinputs = Input(shape=inputShape)\n",
    "\t\tx = inputs\n",
    "\t\t# loop over the number of filters\n",
    "\t\tfor f in filters:\n",
    "\t\t\t# apply a CONV => RELU => BN operation\n",
    "\t\t\tx = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\t\t\tx = BatchNormalization(axis=chanDim)(x)\n",
    "\t\t# flatten the network and then construct our latent vector\n",
    "\t\tvolumeSize = K.int_shape(x)\n",
    "\t\tx = Flatten()(x)\n",
    "\t\tlatent = Dense(latentDim)(x)\n",
    "\t\t# build the encoder model\n",
    "\t\tencoder = Model(inputs, latent, name=\"encoder\")\n",
    "        \n",
    "        \t\t# start building the decoder model which will accept the\n",
    "\t\t# output of the encoder as its inputs\n",
    "\t\tlatentInputs = Input(shape=(latentDim,))\n",
    "\t\tx = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
    "\t\tx = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
    "\t\t# loop over our number of filters again, but this time in\n",
    "\t\t# reverse order\n",
    "\t\tfor f in filters[::-1]:\n",
    "\t\t\t# apply a CONV_TRANSPOSE => RELU => BN operation\n",
    "\t\t\tx = Conv2DTranspose(f, (3, 3), strides=2,\n",
    "\t\t\t\tpadding=\"same\")(x)\n",
    "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\t\t\tx = BatchNormalization(axis=chanDim)(x)\n",
    "\t\t# apply a single CONV_TRANSPOSE layer used to recover the\n",
    "\t\t# original depth of the image\n",
    "\t\tx = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
    "\t\toutputs = Activation(\"sigmoid\")(x)\n",
    "\t\t# build the decoder model\n",
    "\t\tdecoder = Model(latentInputs, outputs, name=\"decoder\")\n",
    "\t\t# our autoencoder is the encoder + decoder\n",
    "\t\tautoencoder = Model(inputs, decoder(encoder(inputs)),\n",
    "\t\t\tname=\"autoencoder\")\n",
    "\t\t# return a 3-tuple of the encoder, decoder, and autoencoder\n",
    "\t\treturn (encoder, decoder, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a520ab2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyimagesearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m matplotlib\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# import the necessary packages\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyimagesearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvautoencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvAutoencoder\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyimagesearch'"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from pyimagesearch.convautoencoder import ConvAutoencoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820b3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
